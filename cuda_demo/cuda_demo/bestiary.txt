	//Matrix in 2D indexing
	float matrix2D[numRows][numCols];
	//Populate
	printf("\nPopulate matrix2D(%d,%d) with double for loop...\n",numRows, numCols);
	for (int row = 0; row < numRows; row++) {
		for (int col = 0; col < numCols; col++) {
			matrix2D[row][col] = row + (float)col / 100;
		}
	}

	//Visualize canonically
	printf("\nVisualize matrix2D(%d,%d) with double for loop...\n", numRows, numCols);
	for (int row = 0; row < numRows; row++) {
		printf("\n");
		for (int col = 0; col < numCols; col++) {
			if (matrix2D[row][col] < 10) {
				printf(" %.2f ", matrix2D[row][col]);
			}
			else {
				printf("%.2f ", matrix2D[row][col]);
			}
		}
	}

	//Visualize matrix2D with 1D indexing, using unflatten()
	printf("\n\nVisualize matrix2D(%d,%d) with one for loop, using int * matIdx = unflatten(iter, %d, %d)...\n", numRows, numCols, numRows, numCols);
	for (int i = 0; i < numRows * numCols; i++) {
		if (i % numCols == 0) printf("\n");
		int * matIdx = unflatten_idx(i, numRows, numCols);
		float output = matrix2D[matIdx[0]][matIdx[1]];
		if ((int)output < 10) {
			printf(" %.2f ", output);
		}
		else {
			printf("%.2f ", output);
		}
	}

	//Matrix in 1D indexing
	float matrix1D[ARRAY_SIZE];
	//Populate
	printf("\n\nPopulate matrix1D(%d,%d) with double for loop, with matrix1D[row*numCols + col] (as used in flatten())...\n", numRows, numCols);
	for (int row = 0; row < numRows; row++) {
		for (int col = 0; col < numCols; col++) {
			matrix1D[row*numCols + col] = row + (float)col/100;
		}
	}

	//Visualize canonically in 1D
	printf("\nVisualize matrix1D(%d,%d) with one for loop...\n", numRows, numCols);
	for (int i = 0; i < ARRAY_SIZE; i++) {
		if (i % numCols == 0) printf("\n");
		if ((int)matrix1D[i] < 10) {
			printf(" %.2f ", matrix1D[i]);
		}
		else {
			printf("%.2f ", matrix1D[i]);
		}
	}
	printf("\n");

	//Visualize canonically by construction in 2D
	printf("\nVisualize matrix1D(%d,%d) with double for loop, using construction indexing...\n", numRows, numCols, numRows, numCols);
	for (int i = 0; i < numRows; i++) {
		printf("\n");
		for (int j = 0; j < numCols; j++) {
			if (matrix1D[i*numCols + j] < 10) {
				printf(" %.2f ", matrix1D[i*numCols + j]);
			}
			else {
				printf("%.2f ", matrix1D[i*numCols + j]);
			}
		}
	}
	
	//Visualize matrix1D with 2D indexing, using flatten()
	printf("\n\nVisualize matrix1D(%d,%d) with double for loop, using flatten(iter*,%d,%d)...\n", numRows, numCols, numRows, numCols);
	for (int row = 0; row < numRows; row++) {
		printf("\n");
		for (int col = 0; col < numCols; col++) {
			int matrixIdx[] = { row, col };
			float output  = matrix1D[flatten_idx(matrixIdx, numRows, numCols)];
			if (output < 10) {
				printf(" %.2f ", output);
			}
			else {
				printf("%.2f ", output);
			}
		}
	}





//CUDA demo 3
/*
=======
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>
#include "gputimer.h"
#define NUM_THREADS 10000000
#define ARRAY_SIZE  100

#define BLOCK_WIDTH 1000

void print_array(int *array, int size)
{
	printf("{ ");
	for (int i = 0; i < size; i++) { printf("%d ", array[i]); }
	printf("}\n");
}

__global__ void increment_naive(int *g)
{
	// which thread is this?
	int i = blockIdx.x * blockDim.x + threadIdx.x;

	// each thread to increment consecutive elements, wrapping at ARRAY_SIZE
	i = i % ARRAY_SIZE;
	g[i] = g[i] + 1;
}

__global__ void increment_atomic(int *g)
{
	// which thread is this?
	int i = blockIdx.x * blockDim.x + threadIdx.x;

	// each thread to increment consecutive elements, wrapping at ARRAY_SIZE
	i = i % ARRAY_SIZE;
	atomicAdd(&g[i], 1);
}

int main(int argc, char **argv)
{
	GpuTimer timer;
	printf("%d total threads in %d blocks writing into %d array elements\n",
		NUM_THREADS, NUM_THREADS / BLOCK_WIDTH, ARRAY_SIZE);

	// declare and allocate host memory
	int *h_array = new int[ARRAY_SIZE]; //forum suggestion against stack overflow
	//int h_array[ARRAY_SIZE]; //original code
	const int ARRAY_BYTES = ARRAY_SIZE * sizeof(int);

	// declare, allocate, and zero out GPU memory
	int * d_array;
	cudaMalloc((void **)&d_array, ARRAY_BYTES);
	cudaMemset((void *)d_array, 0, ARRAY_BYTES);

	// launch the kernel - comment out one of these
	timer.Start();

	// Instructions: This program is needed for the next quiz
	// uncomment increment_naive to measure speed and accuracy 
	// of non-atomic increments or uncomment increment_atomic to
	// measure speed and accuracy of  atomic icrements
	// increment_naive<<<NUM_THREADS/BLOCK_WIDTH, BLOCK_WIDTH>>>(d_array);
	increment_atomic << <NUM_THREADS / BLOCK_WIDTH, BLOCK_WIDTH >> >(d_array);
	timer.Stop();

	// copy back the array of sums from GPU and print
	cudaMemcpy(h_array, d_array, ARRAY_BYTES, cudaMemcpyDeviceToHost);
	print_array(h_array, ARRAY_SIZE);
	printf("Time elapsed = %g ms\n", timer.Elapsed());

	// free GPU memory allocation and exit
	cudaFree(d_array);
	std::cin.ignore();
	return 0;
}
*/

/*
//CUDA demo 2
#define NUM_BLOCKS 16
#define BLOCK_WIDTH 1

__global__ void hello()
{
	printf("Hello world! I'm a thread in block %d\n", blockIdx.x);
}


int main(int argc, char **argv)
{
	// launch the kernel
	hello << <NUM_BLOCKS, BLOCK_WIDTH >> >();

	// force the printf()s to flush
	cudaDeviceSynchronize();

	printf("That's all!\n");

	std::cin.ignore();
	return 0;
}
*/

//CUDA demo 1
/*
__global__ void cube(float * d_out, float * d_in) {
	int idx = threadIdx.x;
	float f = d_in[idx];
	d_out[idx] = f*f*f;
}

int main(int argc, char ** argv) {
	const int ARRAY_SIZE = 96;
	const int ARRAY_BYTES = ARRAY_SIZE * sizeof(float);

	// generate the input array on the host

__global__ void cube(float *d_out, float *d_in) {
	int idx = threadIdx.x;
	float f = d_in[idx];
	d_out[idx] = f * f * f;
}

int main(int argc, char **argv) {
	const int ARRAY_SIZE = 1024;
	const int ARRAY_BYTES = ARRAY_SIZE * sizeof(float);

	float h_in[ARRAY_SIZE];
	for (int i = 0; i < ARRAY_SIZE; i++) {
		h_in[i] = float(i);
	}
	float h_out[ARRAY_SIZE];


	// declare GPU memory pointers

	// gpu memory pointers

	float * d_in;
	float * d_out;

	// allocate GPU memory

	cudaMalloc((void**)&d_in, ARRAY_BYTES);
	cudaMalloc((void**)&d_out, ARRAY_BYTES);

	// transfer the array to the GPU
	cudaMemcpy(d_in, h_in, ARRAY_BYTES, cudaMemcpyHostToDevice);

	// launch the kernel
	cube << <1, ARRAY_SIZE >> > (d_out, d_in);

	// copy back the result array to the CPU
	cudaMemcpy(h_out, d_out, ARRAY_BYTES, cudaMemcpyDeviceToHost);

	// print out the resulting array

	cudaMalloc((void **) &d_in, ARRAY_BYTES);
	cudaMalloc((void **)&d_out, ARRAY_BYTES);

	cudaMemcpy(d_in, h_in, ARRAY_BYTES, cudaMemcpyHostToDevice);
	cube<<<1, ARRAY_SIZE>>>(d_out, d_in);
	cudaMemcpy(h_out, d_out, ARRAY_BYTES, cudaMemcpyDeviceToHost);


	for (int i = 0; i < ARRAY_SIZE; i++) {
		printf("%f", h_out[i]);
		printf(((i % 4) != 3) ? "\t" : "\n");
	}



	// deallocate GPU memory
	cudaFree(d_in);
	cudaFree(d_out);

	std::cin.ignore();

	return 0;

}
*/

}

